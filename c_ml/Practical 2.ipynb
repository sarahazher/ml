{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d77233b-3733-4dbc-8b39-3ca7efa07f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Analysis:\n",
    "# A. Predict the price of the Uber ride from a given pickup point to the agreed drop-off\n",
    "# location. Perform following tasks:\n",
    "# 1. Pre-process the dataset.\n",
    "# 2. Identify outliers.\n",
    "# 3. Check the correlation.\n",
    "# 4. Implement linear regression and ridge, Lasso regression models.\n",
    "# 5. Evaluate the models and compare their respective scores like R2, RMSE, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "727df070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "# pandas, numpy, matplotlib: Libraries used for data manipulation, calculations, and visualization.\n",
    "# train_test_split, StandardScaler: Tools for splitting data into training/testing sets and scaling features.\n",
    "# LinearRegression, Ridge, Lasso: Regression models from sklearn.\n",
    "# r2_score, mean_squared_error: Evaluation metrics for model performance.\n",
    "# SimpleImputer: Used to handle missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4ea900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0                            key  fare_amount  \\\n",
      "0         24238194    2015-05-07 19:52:06.0000003          7.5   \n",
      "1         27835199    2009-07-17 20:04:56.0000002          7.7   \n",
      "2         44984355   2009-08-24 21:45:00.00000061         12.9   \n",
      "3         25894730    2009-06-26 08:22:21.0000001          5.3   \n",
      "4         17610152  2014-08-28 17:47:00.000000188         16.0   \n",
      "...            ...                            ...          ...   \n",
      "199995    42598914   2012-10-28 10:49:00.00000053          3.0   \n",
      "199996    16382965    2014-03-14 01:09:00.0000008          7.5   \n",
      "199997    27804658   2009-06-29 00:42:00.00000078         30.9   \n",
      "199998    20259894    2015-05-20 14:56:25.0000004         14.5   \n",
      "199999    11951496   2010-05-15 04:08:00.00000076         14.1   \n",
      "\n",
      "                pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
      "0       2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
      "1       2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
      "2       2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
      "3       2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
      "4       2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
      "...                         ...               ...              ...   \n",
      "199995  2012-10-28 10:49:00 UTC        -73.987042        40.739367   \n",
      "199996  2014-03-14 01:09:00 UTC        -73.984722        40.736837   \n",
      "199997  2009-06-29 00:42:00 UTC        -73.986017        40.756487   \n",
      "199998  2015-05-20 14:56:25 UTC        -73.997124        40.725452   \n",
      "199999  2010-05-15 04:08:00 UTC        -73.984395        40.720077   \n",
      "\n",
      "        dropoff_longitude  dropoff_latitude  passenger_count  \n",
      "0              -73.999512         40.723217                1  \n",
      "1              -73.994710         40.750325                1  \n",
      "2              -73.962565         40.772647                1  \n",
      "3              -73.965316         40.803349                3  \n",
      "4              -73.973082         40.761247                5  \n",
      "...                   ...               ...              ...  \n",
      "199995         -73.986525         40.740297                1  \n",
      "199996         -74.006672         40.739620                1  \n",
      "199997         -73.858957         40.692588                2  \n",
      "199998         -73.983215         40.695415                1  \n",
      "199999         -73.985508         40.768793                1  \n",
      "\n",
      "[200000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"uber.csv\")\n",
    "\n",
    "# view dataset\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6537fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "# print(df['pickup_datetime'])\n",
    "df['hour'] = df['pickup_datetime'].dt.hour\n",
    "# print(df['hour'])\n",
    "df['day_of_week'] = df['pickup_datetime'].dt.dayofweek\n",
    "# print(df['day_of_week'])\n",
    "\n",
    "#pd.to_datetime(...): Converts pickup_datetime column from string to datetime format, allowing us to extract time-related information.\n",
    "#df['hour'] = ...: Adds a new column hour representing the hour of day when the ride was picked up.\n",
    "#df['day_of_week'] = ...: Adds a day_of_week column representing the day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a722874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0                            key  fare_amount  \\\n",
      "0         24238194    2015-05-07 19:52:06.0000003          7.5   \n",
      "1         27835199    2009-07-17 20:04:56.0000002          7.7   \n",
      "2         44984355   2009-08-24 21:45:00.00000061         12.9   \n",
      "3         25894730    2009-06-26 08:22:21.0000001          5.3   \n",
      "4         17610152  2014-08-28 17:47:00.000000188         16.0   \n",
      "...            ...                            ...          ...   \n",
      "199995    42598914   2012-10-28 10:49:00.00000053          3.0   \n",
      "199996    16382965    2014-03-14 01:09:00.0000008          7.5   \n",
      "199997    27804658   2009-06-29 00:42:00.00000078         30.9   \n",
      "199998    20259894    2015-05-20 14:56:25.0000004         14.5   \n",
      "199999    11951496   2010-05-15 04:08:00.00000076         14.1   \n",
      "\n",
      "                 pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
      "0      2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
      "1      2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
      "2      2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
      "3      2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
      "4      2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
      "...                          ...               ...              ...   \n",
      "199995 2012-10-28 10:49:00+00:00        -73.987042        40.739367   \n",
      "199996 2014-03-14 01:09:00+00:00        -73.984722        40.736837   \n",
      "199997 2009-06-29 00:42:00+00:00        -73.986017        40.756487   \n",
      "199998 2015-05-20 14:56:25+00:00        -73.997124        40.725452   \n",
      "199999 2010-05-15 04:08:00+00:00        -73.984395        40.720077   \n",
      "\n",
      "        dropoff_longitude  dropoff_latitude  passenger_count  hour  \\\n",
      "0              -73.999512         40.723217                1    19   \n",
      "1              -73.994710         40.750325                1    20   \n",
      "2              -73.962565         40.772647                1    21   \n",
      "3              -73.965316         40.803349                3     8   \n",
      "4              -73.973082         40.761247                5    17   \n",
      "...                   ...               ...              ...   ...   \n",
      "199995         -73.986525         40.740297                1    10   \n",
      "199996         -74.006672         40.739620                1     1   \n",
      "199997         -73.858957         40.692588                2     0   \n",
      "199998         -73.983215         40.695415                1    14   \n",
      "199999         -73.985508         40.768793                1     4   \n",
      "\n",
      "        day_of_week  \n",
      "0                 3  \n",
      "1                 4  \n",
      "2                 0  \n",
      "3                 4  \n",
      "4                 3  \n",
      "...             ...  \n",
      "199995            6  \n",
      "199996            4  \n",
      "199997            0  \n",
      "199998            2  \n",
      "199999            5  \n",
      "\n",
      "[200000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# check datasets for more columns we added 'hour' and 'day_of_week' column\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77484ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['Unnamed: 0', 'key', 'pickup_datetime'])\n",
    "#df.drop(columns=...): Removes columns that aren't useful for prediction, like the unnamed index column, key, and pickup_datetime.\n",
    "#print(df): Verifies that the columns have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d7daab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
      "0               7.5        -73.999817        40.738354         -73.999512   \n",
      "1               7.7        -73.994355        40.728225         -73.994710   \n",
      "2              12.9        -74.005043        40.740770         -73.962565   \n",
      "3               5.3        -73.976124        40.790844         -73.965316   \n",
      "4              16.0        -73.925023        40.744085         -73.973082   \n",
      "...             ...               ...              ...                ...   \n",
      "199995          3.0        -73.987042        40.739367         -73.986525   \n",
      "199996          7.5        -73.984722        40.736837         -74.006672   \n",
      "199997         30.9        -73.986017        40.756487         -73.858957   \n",
      "199998         14.5        -73.997124        40.725452         -73.983215   \n",
      "199999         14.1        -73.984395        40.720077         -73.985508   \n",
      "\n",
      "        dropoff_latitude  passenger_count  hour  day_of_week  \n",
      "0              40.723217                1    19            3  \n",
      "1              40.750325                1    20            4  \n",
      "2              40.772647                1    21            0  \n",
      "3              40.803349                3     8            4  \n",
      "4              40.761247                5    17            3  \n",
      "...                  ...              ...   ...          ...  \n",
      "199995         40.740297                1    10            6  \n",
      "199996         40.739620                1     1            4  \n",
      "199997         40.692588                2     0            0  \n",
      "199998         40.695415                1    14            2  \n",
      "199999         40.768793                1     4            5  \n",
      "\n",
      "[200000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# check datasets for removal of columns we removed 'first_column with no name', 'key' and 'pickup_datetime' column\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953b4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "#SimpleImputer(strategy='mean'): Creates an imputer that replaces missing values with the mean of each column.\n",
    "#df_imputed = pd.DataFrame(...): Applies the imputer to the dataset, creating a new DataFrame with no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3cc569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = df_imputed.drop(columns=['fare_amount'])  # create new dataset ignoring 'fare_amount' column\n",
    "y = df_imputed['fare_amount']  # create a series of only 'fare_amount' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbcf2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#train_test_split(...): Splits X and y into training and testing sets, with 20% of data as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95669338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# scaler = StandardScaler(): Initializes the scaler to standardize features.\n",
    "# X_train_scaled = scaler.fit_transform(...): Scales X_train to have a mean of 0 and standard deviation of 1.\n",
    "# X_test_scaled = scaler.transform(...): Scales X_test based on the X_train scaling parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3404f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Linear Regression\n",
    "lr_model = LinearRegression() #Initializes a Linear Regression model.\n",
    "lr_model.fit(X_train_scaled, y_train)  # Fits the model to the training data.\n",
    "y_pred_lr = lr_model.predict(X_test_scaled) #Uses the model to predict fare_amount for X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea140022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)  # You can experiment with different alpha values\n",
    "#Initializes Ridge Regression with a penalty (alpha) of 1.0 to avoid overfitting.\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "574e03f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Lasso Regression\n",
    "lasso_model = Lasso(alpha=0.1)  # You can experiment with different alpha values\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = lasso_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16245eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"{model_name} - R2 Score: {r2:.4f}, RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42a3de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - R2 Score: 0.0007, RMSE: 10.31\n",
      "Ridge Regression - R2 Score: 0.0007, RMSE: 10.31\n",
      "Lasso Regression - R2 Score: 0.0003, RMSE: 10.31\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, y_pred_lr, \"Linear Regression\")\n",
    "evaluate_model(y_test, y_pred_ridge, \"Ridge Regression\")\n",
    "evaluate_model(y_test, y_pred_lasso, \"Lasso Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06474cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Understanding Regression Models in General\n",
    "# Regression is a statistical method used to model and analyze relationships between a dependent variable (the target we’re trying to predict) and one or more independent variables (features or predictors). It’s commonly used to predict numerical values, like prices, quantities, and scores.\n",
    "\n",
    "# Linear Regression: This is the simplest regression model. It assumes a linear relationship between the input variables and the output variable. The goal is to find the \"line of best fit\" that minimizes the difference between the actual data points and the predictions made by this line.\n",
    "\n",
    "# Ridge Regression: A type of linear regression that includes a penalty (called regularization) to avoid overfitting. This penalty term, defined by alpha, reduces the impact of variables that have little predictive power by shrinking their coefficients, helping the model generalize better to new data.\n",
    "\n",
    "# Lasso Regression: Like Ridge, Lasso regression also applies regularization but does so differently. It can shrink some feature coefficients entirely to zero, effectively selecting a subset of predictors. This makes Lasso useful for identifying the most important features in a dataset, as it essentially \"drops\" less important ones.\n",
    "\n",
    "# 2. Breaking Down Each Section of Code\n",
    "# Let’s discuss how each code section contributes to creating and evaluating these regression models.\n",
    "\n",
    "# 2.1. Data Preprocessing\n",
    "# Data preprocessing is about making the dataset ready for modeling. Here’s what each preprocessing step accomplishes:\n",
    "\n",
    "# Date Parsing:\n",
    "\n",
    "# By extracting the hour of the day and day of the week from pickup_datetime, the model can identify patterns in fare pricing based on time factors (e.g., higher fares during rush hours or weekends).\n",
    "# Dropping Columns:\n",
    "\n",
    "# Columns that don’t contribute to fare prediction (like pickup_datetime, Unnamed: 0, and key) are removed. This avoids noise in the model, improving its performance.\n",
    "# Handling Missing Values:\n",
    "\n",
    "# Missing data can skew predictions or make the model unstable. Here, the missing values are replaced with the mean of each column using SimpleImputer, which ensures all rows are complete.\n",
    "# Feature Scaling:\n",
    "\n",
    "# Scaling ensures that all features have similar ranges, which is especially important for models like Ridge and Lasso that are sensitive to the magnitude of feature values. StandardScaler standardizes data to have a mean of 0 and a standard deviation of 1.\n",
    "# 2.2. Implementing Regression Models\n",
    "# Each regression model has its specific characteristics:\n",
    "\n",
    "# Linear Regression:\n",
    "\n",
    "# Finds the line that best fits the data by minimizing the sum of squared differences between actual and predicted fare values.\n",
    "# Ridge Regression:\n",
    "\n",
    "# Adds a penalty proportional to the square of the coefficients. This reduces the influence of features with less predictive power, making the model more robust to outliers and overfitting.\n",
    "# Lasso Regression:\n",
    "\n",
    "# Adds a penalty based on the absolute values of coefficients, which can drive some coefficients to zero. This is useful for feature selection, as it effectively removes unimportant features.\n",
    "# 2.3. Evaluating Model Performance\n",
    "# The models are evaluated using:\n",
    "\n",
    "# R² Score:\n",
    "\n",
    "# R-squared measures how well the model explains the variation in the target variable. Higher values mean the model captures more of the data’s variance, indicating a better fit.\n",
    "# RMSE (Root Mean Squared Error):\n",
    "\n",
    "# RMSE provides an average measure of the difference between actual and predicted values. Lower values indicate better model accuracy.\n",
    "# 3. Real-World Applications of Each Model\n",
    "# Let’s look at practical situations where these models could be applied.\n",
    "\n",
    "# Linear Regression\n",
    "\n",
    "# House Price Prediction: You could predict house prices based on features like size, location, number of bedrooms, and age. A linear relationship often approximates such scenarios.\n",
    "# Stock Price Prediction: Linear regression can offer insights into price movement over time based on factors like historical prices or economic indicators, though it’s often used as a simple baseline model in this case.\n",
    "# Ridge Regression\n",
    "\n",
    "# Predicting Loan Default Rates: A bank could use ridge regression to predict the likelihood of loan defaults based on multiple customer attributes (e.g., income, debt, and credit score). Ridge regression helps manage the noise from many variables and reduces overfitting.\n",
    "# Medical Costs Prediction: In healthcare, ridge regression can help predict treatment costs based on numerous patient attributes. The regularization can prevent overfitting, especially with many variables.\n",
    "# Lasso Regression\n",
    "\n",
    "# Feature Selection in Marketing: Lasso regression could help a company decide which customer attributes (like age, location, spending habits) are most important when predicting the likelihood of making a purchase. Unimportant variables are automatically zeroed out, leaving only significant ones.\n",
    "# Customer Churn Prediction: In telecommunications, companies can predict customer churn by identifying important features (e.g., call frequency, support ticket history) while ignoring less relevant ones.\n",
    "# 4. How the Code Works in Practice\n",
    "# In real applications:\n",
    "\n",
    "# Data Preprocessing is a crucial step. Poor data preparation can lead to misleading results or overfitting. Handling missing values, transforming data, and scaling all ensure that the model has the best conditions to learn from the data.\n",
    "\n",
    "# Model Selection:\n",
    "\n",
    "# Linear Regression can work well when there’s a straightforward relationship between variables.\n",
    "# Ridge and Lasso are beneficial when dealing with complex datasets with many features and potential multicollinearity (where features are correlated with each other). These models help create more stable predictions that generalize well to new data.\n",
    "# By applying these models to predict Uber fares, you can see the impact of time-based factors (e.g., peak hours) and geographical factors (e.g., distance traveled) on pricing. Comparing the performance of each model allows you to choose the best approach depending on the data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276de08-9c9e-4610-bbef-595da706a94a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
